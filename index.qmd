---
title: "AB Testing is An Optimization Problem"
subtitle: My Journey to Bayesian Testing
author: "Russ Zaliznyak"
date: "2025-08-05"
execute:
  echo: false
format: 
  html: 
    toc: true
    toc-expand: true
    toc-indent: 1em
---

# Introduction

I argue that significance testing, as traditionally applied in AB experiments, is often misaligned with business goals. While these statistical methods aim to minimize false positives, real business impact is frequently driven by avoiding false negatives — missed opportunities to create value.

Below I show why standard thresholds like α = 0.05 are arbitrary and can distort decision-making. I introduce Bayesian testing as a more practical alternative, and demonstrate — through discussion and simulation — how it better supports value-driven experimentation.

By reframing AB testing around expected value and decision quality, I move beyond rigid thresholds toward practical impact — treating experimentation as an optimization problem, not just a statistical exercise.

# Significance Testing

## Misaligned Goals

**Significance Testing**  is designed to rigorously control the frequency of false positives. If you're writing physics papers or claiming groundbreaking scientific discoveries, it's the perfect tool.

In these fields, false positives are extremely costly — both reputationally and scientifically. That’s why physicists often require 5-sigma evidence — about a 1 in 3.5 million chance that the result is a fluke.

But significance testing says nothing about the most important business questions:

Which decision has the highest expected return — ending the test, running it longer, or taking action now?

## Misaligned Costs

Most companies default to a significance threshold of **α = 0.05** and statistical power of **1 – β = 0.80**.
In practical terms, that means the test is designed to avoid **false positives** four times more aggressively than **false negatives**.

But in most business settings, **false positives aren’t that costly**. We thought a new button color improved conversion — turns out it didn’t. **So what?** The variant was flat, not disastrous.

But missing a true winner? That’s a lost opportunity — and sometimes, **a costly one**.

**What's the optimal balance to strike?**

# Bayesian Testing

## Aligning Goals

The moment you ask, “What’s the expected value of this decision?”, you’ve entered Bayesian territory. You stop obsessing over p-values and start focusing on the projected impact of your actions.

Bayesian testing isn’t a new set of formulas — it’s a philosophical shift. One that aligns statistical thinking with how businesses actually need to make decisions.




